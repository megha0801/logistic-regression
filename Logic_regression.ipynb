{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Logistic Regression, and how does it differ from Linear Regression?\n",
        "\n",
        "-> Logistic Regression and Linear Regression are both supervised learning algorithms used in statistics and machine learning, but they are used for different types of problems and have key differences:\n",
        "\n",
        "-> Logistic Regression:\n",
        "Purpose: Used for classification problems, especially binary classification (e.g., yes/no, 0/1).\n",
        "\n",
        "Output: Predicts the probability that a given input belongs to a certain class.\n",
        "\n",
        "Function Used: Uses the sigmoid (logistic) function to map any real-valued number into the range 0 to 1.\n",
        "\n",
        "-> Linear Regression:\n",
        "Purpose: Used for regression problems, i.e., predicting continuous numeric values.\n",
        "\n",
        "Output: Predicts a real-valued number (e.g., house price, temperature).\n",
        "\n",
        "Function Used: Uses a linear function to model the relationship between input variables and output.\n"
      ],
      "metadata": {
        "id": "_iv2kNqfeSsu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What is the mathematical equation of Logistic Regression?\n",
        "\n",
        "-> The mathematical equation of Logistic Regression combines a linear equation with the sigmoid (logistic) function to produce a probability between 0 and 1.\n",
        "\n"
      ],
      "metadata": {
        "id": "ngMWSDidgys2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Why do we use the Sigmoid function in Logistic Regression?\n",
        "\n",
        "-> We use the sigmoid function in Logistic Regression because it transforms the output of a linear equation into a probability, which is essential for classification tasks.\n",
        "\n",
        "1. Probability output\n",
        "\n",
        "2. Threshold-based classification\n",
        "\n",
        "3. Differentiable function\n",
        "\n",
        "4. Non-linear transformation\n"
      ],
      "metadata": {
        "id": "wku3ge2IhDEI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What is the cost function of Logistic Regression?\n",
        "\n",
        "-> In Logistic Regression, the Mean Squared Error (MSE) used in Linear Regression does not work well because the sigmoid function is non-linear and MSE leads to a non-convex cost function. So, we use the Log Loss or Binary Cross-Entropy Loss instead.\n",
        "\n"
      ],
      "metadata": {
        "id": "FJxiQBPBhl99"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. What is Regularization in Logistic Regression? Why is it needed?\n",
        "\n",
        "-> Regularization is a technique used in Logistic Regression (and other models) to prevent overfitting by penalizing large coefficients in the model.\n",
        "\n",
        "It modifies the cost function by adding a penalty term based on the size of the model's weights (coefficients).\n",
        "\n"
      ],
      "metadata": {
        "id": "CWH6rI6_hyfT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Explain the difference between Lasso, Ridge, and Elastic Net regression.\n",
        "\n",
        "-> Here's a clear comparison of Lasso, Ridge, and Elastic Net regression — all are types of regularized regression techniques used to prevent overfitting and improve model generalization.\n",
        "\n",
        " 1. Ridge Regression (L2 Regularization)\n",
        " 2. Lasso Regression (L1 Regularization)\n",
        " 3. Elastic Net Regression (Combination of L1 & L2)"
      ],
      "metadata": {
        "id": "tsgQgOYpiKwU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. When should we use Elastic Net instead of Lasso or Ridge?\n",
        "\n",
        "->\n",
        "1. When You Have Many Correlated Features\n",
        "\n",
        "-> Lasso tends to pick one feature from a group of correlated features and ignore the rest.\n",
        "\n",
        "-> Elastic Net can keep multiple correlated features, giving more stable and balanced results.\n",
        "\n",
        "2. When the Number of Features (p) > Number of Samples (n)\n",
        "\n",
        "-> In high-dimensional settings (e.g., text data, genomics), Lasso may select too few features or be unstable.\n",
        "\n",
        "-> Elastic Net handles this better by combining the robustness of Ridge and the sparsity of Lasso.\n",
        "\n",
        "3. When You Want Both Feature Selection and Regularization\n",
        "\n",
        "-> Lasso does feature selection but can be unstable.\n",
        "\n",
        "-> Ridge does regularization but keeps all features.\n",
        "\n",
        "-> Elastic Net does both, and gives you a tunable balance via the mixing parameter 𝛼."
      ],
      "metadata": {
        "id": "JmdhkRc1Hmk9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is the impact of the regularization parameter (λ) in Logistic Regression?\n",
        "\n",
        "->The regularization parameter\n",
        "λ (lambda) in Logistic Regression controls the strength of the penalty applied to the model's coefficients. It has a direct impact on the model's complexity and performance."
      ],
      "metadata": {
        "id": "coTyXtNeIgY8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What are the key assumptions of Logistic Regression?\n",
        "\n",
        "->\n",
        "\n",
        "1. Binary or Categorical Outcome\n",
        "2. Independence of Observations\n",
        "3. Linearity of Logit\n",
        "4. No or Little Multicollinearity\n",
        "5. Large Sample Size\n",
        "6. No Outliers with High Influence\n",
        "7. Meaningful Features"
      ],
      "metadata": {
        "id": "SAlstEMQItfP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What are some alternatives to Logistic Regression for classification tasks?\n",
        "\n",
        "-> Here are several strong alternatives to Logistic Regression for classification tasks, depending on your data characteristics and needs:\n",
        "\n",
        "1. Decision Trees\n",
        "2. Random Forest\n",
        "3. Gradient Boosting (e.g., XGBoost, LightGBM, CatBoost)\n",
        "4. Support Vector Machines (SVM)\n",
        "5. k-Nearest Neighbors (k-NN)\n",
        "6. Naive Bayes\n",
        "7. Neural Networks (MLP)\n",
        "8. Linear Discriminant Analysis (LDA)"
      ],
      "metadata": {
        "id": "k_hou1ntJs4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. What are Classification Evaluation Metrics?\n",
        "\n",
        "-> When evaluating classification models (like Logistic Regression, Random Forest, etc.), it's important to measure how well they perform. Here are the most commonly used evaluation metrics:"
      ],
      "metadata": {
        "id": "ayy8EkVjKeyO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. How does class imbalance affect Logistic Regression?\n",
        "\n",
        "-> Class imbalance can negatively affect Logistic Regression by leading to biased predictions, where the model favors the majority class and performs poorly on the minority class—often the class we care about most."
      ],
      "metadata": {
        "id": "moRE50jYKr6Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What is Hyperparameter Tuning in Logistic Regression?\n",
        "\n",
        "-> Hyperparameter tuning is the process of optimizing the model settings (hyperparameters) that are not learned from the data but significantly affect model performance. For Logistic Regression, tuning helps improve accuracy, prevent overfitting, and balance bias-variance trade-offs."
      ],
      "metadata": {
        "id": "pwF-ZqUqK57h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. What are different solvers in Logistic Regression? Which one should be used?\n",
        "\n",
        "-> In logistic regression, a solver is the algorithm used to optimize the cost function. Different solvers are available based on the size of the dataset and the type of regularization used.\n",
        "\n",
        "1. liblinear\n",
        "Type: Coordinate descent\n",
        "\n",
        "Supports: L1 and L2 penalties\n",
        "\n",
        "Best for: Small datasets, binary classification\n",
        "\n",
        "Limitations: Not suitable for large datasets or multinomial problems\n",
        "\n",
        "Use when: You want L1 regularization or interpretable sparse models.\n",
        "\n",
        "2. lbfgs\n",
        "Type: Quasi-Newton (Limited-memory BFGS)\n",
        "\n",
        "Supports: L2 penalty only\n",
        "\n",
        "Best for: Medium to large datasets, multinomial classification\n",
        "\n",
        "Fast & accurate\n",
        "\n",
        "Use when: You want speed, and don’t need L1 or ElasticNet penalties.\n",
        "\n",
        "3. newton-cg\n",
        "Type: Newton’s method with conjugate gradient\n",
        "\n",
        "Supports: L2 penalty\n",
        "\n",
        "Best for: Multinomial classification, large datasets\n",
        "\n",
        "Use when: Dealing with large, multiclass problems.\n",
        "\n",
        "4. sag (Stochastic Average Gradient)\n",
        "Type: Stochastic optimization\n",
        "\n",
        "Supports: L2 penalty\n",
        "\n",
        "Best for: Very large datasets, especially with many samples\n",
        "\n",
        "Requires: Features must be scaled\n",
        "\n",
        " Use when: Dataset is huge and sparse.\n",
        "\n",
        "  5. saga\n",
        "Type: Variant of SAG, supports more penalties\n",
        "\n",
        "Supports: L1, L2, ElasticNet\n",
        "\n",
        "Best for: Large-scale datasets with sparse data\n",
        "\n",
        "Use when: You want to use ElasticNet or scale to large problems.\n",
        "\n"
      ],
      "metadata": {
        "id": "PJ1xE1wELIoh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. How is Logistic Regression extended for multiclass classification?\n",
        "\n",
        "->\n",
        "1. One-vs-Rest (OvR) / One-vs-All (OvA)\n",
        "For K classes, build K separate binary classifiers.\n",
        "\n",
        "Each classifier predicts whether the sample belongs to its class or not (vs. all other classes).\n",
        "\n",
        "The class with the highest predicted probability wins.\n",
        "\n",
        "Default strategy in many libraries, including scikit-learn.\n",
        "\n",
        "2. Multinomial Logistic Regression (Softmax Regression)\n",
        "Directly models the probabilities of all classes together.\n",
        "\n",
        "Uses the softmax function to generalize sigmoid to multiple classes.\n",
        "\n",
        "Predicts class probabilities for all K classes simultaneously."
      ],
      "metadata": {
        "id": "xrLaeCtvQhoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. What are the advantages and disadvantages of Logistic Regression?\n",
        "\n",
        "->\n",
        "\n",
        "-> Advantages\n",
        "\n",
        "1. Simple and Interpretable\n",
        "\n",
        "Easy to understand coefficients as log-odds.\n",
        "\n",
        "Outputs probabilities, useful for decision-making.\n",
        "\n",
        "2. Efficient and Fast\n",
        "\n",
        "Works well on small to medium-sized datasets.\n",
        "\n",
        "Computationally inexpensive compared to complex models.\n",
        "\n",
        "3. Probabilistic Output\n",
        "\n",
        "Provides predicted probabilities, not just class labels.\n",
        "\n",
        "Useful in applications needing risk assessment.\n",
        "\n",
        "4. Works Well with Linearly Separable Data\n",
        "\n",
        "Performs well when the relationship between features and log-odds is linear.\n",
        "\n",
        "5. Can be Regularized\n",
        "\n",
        "Supports L1, L2, and Elastic Net regularization to prevent overfitting.\n",
        "\n",
        "6. Less Prone to Overfitting (with regularization)\n",
        "\n",
        "Compared to complex models like decision trees or neural networks.\n",
        "\n",
        "-> Disadvantages\n",
        "\n",
        "1. Assumes Linearity in Log-Odds\n",
        "\n",
        "Struggles if the relationship between predictors and outcome is non-linear.\n",
        "\n",
        "2. Not Great with Complex Patterns\n",
        "\n",
        "Cannot naturally model interactions or complex boundaries without feature engineering.\n",
        "\n",
        "3. Sensitive to Outliers and Multicollinearity\n",
        "\n",
        "Outliers can skew the model, and correlated features affect coefficient stability.\n",
        "\n",
        "4. Poor Performance with Imbalanced Data\n",
        "\n",
        "Tends to be biased toward the majority class unless handled explicitly.\n",
        "\n",
        "5. Limited to Binary or Multinomial Classification\n",
        "\n",
        "Not suitable for regression tasks or ranking problems.\n",
        "\n",
        "6. Requires Careful Feature Scaling\n",
        "\n",
        "Especially when using regularization and gradient-based solvers.\n"
      ],
      "metadata": {
        "id": "BdlqfZPfRFo_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17 What are some use cases of Logistic Regression?\n",
        "\n",
        "->Logistic Regression is widely used because of its simplicity and interpretability, especially for binary classification problems. Here are some common use cases across various domains:\n",
        "\n",
        "1. Medical Diagnosis\n",
        "2. Credit scoring / finance\n",
        "3. Marketing\n",
        "4. Social sciences\n",
        "5. Text classification\n",
        "6. Manufacturing\n",
        "7. Web analytics\n"
      ],
      "metadata": {
        "id": "vwKt1uvPSdHk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What is the difference between Softmax Regression and Logistic Regression?\n",
        "\n",
        "-> Logistic Regression\n",
        "Purpose: Binary classification (two classes only).\n",
        "\n",
        "Output: Probability of a sample belonging to one class (e.g., class 1), with the other class probability = 1 - that.\n",
        "\n",
        "Function: Uses the sigmoid function to map linear combinations of features to probabilities between 0 and 1.\n",
        "\n",
        "-> Softmax Regression (Multinomial Logistic Regression)\n",
        "Purpose: Multiclass classification (more than two classes).\n",
        "\n",
        "Output: Probabilities for each class (all probabilities sum to 1).\n",
        "\n",
        "Function: Uses the softmax function, which generalizes sigmoid to multiple classes."
      ],
      "metadata": {
        "id": "D8aElSe5TDzn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?\n",
        "\n",
        "-> 1. One-vs-Rest (OvR)\n",
        "How it works:\n",
        "Trains one binary classifier per class, distinguishing that class vs. all others.\n",
        "\n",
        "Pros:\n",
        "\n",
        "Simple and intuitive.\n",
        "\n",
        "Often faster to train when the number of classes is large.\n",
        "\n",
        "Can work well if classes are well separated.\n",
        "\n",
        "Flexible: each classifier is independent.\n",
        "\n",
        "Cons:\n",
        "\n",
        "May lead to ambiguous predictions if multiple classifiers strongly predict their class.\n",
        "\n",
        "Can be less accurate when classes overlap or are related.\n",
        "\n",
        "Doesn’t model interactions between classes.\n",
        "\n",
        "When to use:\n",
        "\n",
        "Large number of classes.\n",
        "\n",
        "Classes are fairly distinct.\n",
        "\n",
        "Need simpler, faster models.\n",
        "\n",
        "2. Softmax (Multinomial Logistic Regression)\n",
        "How it works:\n",
        "Trains a single model that simultaneously models probabilities for all classes using the softmax function.\n",
        "\n",
        "Pros:\n",
        "\n",
        "Models all classes jointly, capturing relationships.\n",
        "\n",
        "Usually more accurate when classes overlap or are related.\n",
        "\n",
        "Provides a proper probability distribution over classes.\n",
        "\n",
        "Better calibrated probabilities.\n",
        "\n",
        "Cons:\n",
        "\n",
        "Can be slower to train, especially with many classes or large datasets.\n",
        "\n",
        "Requires solvers that support multinomial loss (e.g., 'lbfgs', 'saga').\n",
        "\n",
        "When to use:\n",
        "\n",
        "When classes are not well separated or are related.\n",
        "\n",
        "You want better probability estimates.\n",
        "\n",
        "Dataset size and computational resources allow."
      ],
      "metadata": {
        "id": "ojvagdV9TckS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. How do we interpret coefficients in Logistic Regression?\n",
        "\n",
        "->\n",
        "1. Logistic Regression Coefficients (β)\n",
        "2. Mathematical Form\n",
        "3. Interpretation of 𝛽𝑗\n",
        "4. Odds Ratio\n",
        "5. Example\n",
        "6. Note on Feature Scaling"
      ],
      "metadata": {
        "id": "q5VzHWSST11e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practical:**"
      ],
      "metadata": {
        "id": "C4AnKPBm4C3Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic\n",
        "Regression, and prints the model accuracy."
      ],
      "metadata": {
        "id": "Wd0utZ_vlz8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "\n",
        "X = X[y != 2]\n",
        "y = y[y != 2]\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Model Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IBnEXzym6mx",
        "outputId": "a38da8e2-2a84-47d0-83ff-dad22349f0ad"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1')\n",
        "and print the model accuracy."
      ],
      "metadata": {
        "id": "uFqJFDchnNSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X = X[y != 2]\n",
        "y = y[y != 2]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = LogisticRegression(penalty='l1', solver='liblinear', C=1.0)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"L1-Regularized Logistic Regression Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx8kLWOcnY5o",
        "outputId": "d8fcc7aa-2835-4274-e9fa-027b890a3e1b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1-Regularized Logistic Regression Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Write a Python program to train Logistic Regression with L2 regularization (Ridge) using\n",
        "LogisticRegression(penalty='l2'). Print model accuracy and coefficients."
      ],
      "metadata": {
        "id": "PY3cmctInxfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X = X[y != 2]\n",
        "y = y[y != 2]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = LogisticRegression(penalty='l2', solver='liblinear', C=1.0)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"L2-Regularized Logistic Regression Accuracy:\", accuracy)\n",
        "print(\"Model Coefficients:\", model.coef_)\n",
        "print(\"Intercept:\", model.intercept_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yuk5lqdLnnWe",
        "outputId": "f5e096be-cc86-4a9a-d6fe-0f482ca51607"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L2-Regularized Logistic Regression Accuracy: 1.0\n",
            "Model Coefficients: [[ 0.76824459 -1.09795391  1.45561898  1.47453658]]\n",
            "Intercept: [0.24425449]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')."
      ],
      "metadata": {
        "id": "ta8bQrDDoHuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X = X[y != 2]\n",
        "y = y[y != 2]\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "model = LogisticRegression(\n",
        "    penalty='elasticnet',\n",
        "    solver='saga',\n",
        "    l1_ratio=0.5,\n",
        "    C=1.0,\n",
        "    max_iter=1000,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Elastic Net Logistic Regression Accuracy:\", accuracy)\n",
        "print(\"Model Coefficients:\", model.coef_)\n",
        "print(\"Intercept:\", model.intercept_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y7Msa1JomXW",
        "outputId": "72bbc96e-e827-4db5-f137-6ada2ce99461"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elastic Net Logistic Regression Accuracy: 1.0\n",
            "Model Coefficients: [[ 0.55135918 -0.97050392  1.64554973  1.63519669]]\n",
            "Intercept: [0.39676139]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Write a Python program to train a Logistic Regression model for multiclass classification using\n",
        "multi_class='ovr."
      ],
      "metadata": {
        "id": "-WS7DdhgpAl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear', C=1.0)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"OvR Multiclass Logistic Regression Accuracy:\", accuracy)\n",
        "print(\"Model Coefficients:\\n\", model.coef_)\n",
        "print(\"Intercept:\\n\", model.intercept_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZ9OFZGRpSbu",
        "outputId": "43178fcb-51b8-4f96-e934-a032d8ba0b7e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OvR Multiclass Logistic Regression Accuracy: 0.9666666666666667\n",
            "Model Coefficients:\n",
            " [[-0.77929311  1.3519912  -1.59627349 -1.42737302]\n",
            " [ 0.25113137 -1.26696209  0.55078399 -0.73931909]\n",
            " [ 0.0180311  -0.20827858  1.73529514  2.39229869]]\n",
            "Intercept:\n",
            " [-1.47992812 -0.84440154 -2.54239507]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic\n",
        "Regression. Print the best parameters and accuracy."
      ],
      "metadata": {
        "id": "2phnlG_OpirP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = LogisticRegression(solver='saga', multi_class='ovr', max_iter=1000)\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
        "print(\"Test Set Accuracy with Best Parameters:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I94xuWZapXUw",
        "outputId": "64219db8-a1c8-4529-8b23-e534a816c942"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 10, 'penalty': 'l1'}\n",
            "Best Cross-Validation Accuracy: 0.95\n",
            "Test Set Accuracy with Best Parameters: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the\n",
        "average accuracy."
      ],
      "metadata": {
        "id": "0AK7QmdDqIJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000, solver='liblinear', multi_class='ovr')\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
        "\n",
        "print(\"Accuracy for each fold:\", scores)\n",
        "print(\"Average Accuracy:\", np.mean(scores))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rz-HpJpUqQFL",
        "outputId": "ce3c4c78-a466-434b-a995-f26bb158514d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for each fold: [0.93333333 0.96666667 0.8        0.93333333 0.86666667]\n",
            "Average Accuracy: 0.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its\n",
        "accuracy."
      ],
      "metadata": {
        "id": "BouPzpxoqeeH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Create and save a sample dataset to CSV\n",
        "data = {\n",
        "    'age': [25, 30, 45, 35, 50, 23, 33, 40],\n",
        "    'income': [50000, 60000, 80000, 75000, 90000, 48000, 62000, 79000],\n",
        "    'student': [0, 1, 0, 1, 0, 1, 0, 1],\n",
        "    'credit_rating': [700, 710, 720, 730, 690, 710, 740, 720],\n",
        "    'target': [0, 1, 0, 1, 0, 1, 0, 1]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "csv_filename = 'sample_data.csv'\n",
        "df.to_csv(csv_filename, index=False)\n",
        "print(f\"CSV file '{csv_filename}' created successfully.\\n\")\n",
        "\n",
        "# Step 2: Load dataset from CSV\n",
        "df = pd.read_csv(csv_filename)\n",
        "\n",
        "# Step 3: Prepare features and target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Step 4: Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Step 5: Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Step 6: Train Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 7: Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Logistic Regression Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqVB8pFPrMe_",
        "outputId": "a0111753-7b1c-4de6-80f7-73861fc72191"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file 'sample_data.csv' created successfully.\n",
            "\n",
            "Logistic Regression Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in\n",
        "Logistic Regression. Print the best parameters and accuracy.\n"
      ],
      "metadata": {
        "id": "GQQp7bhtrUb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import uniform\n",
        "import numpy as np\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000, multi_class='ovr')\n",
        "\n",
        "param_dist = {\n",
        "    'C': uniform(0.01, 10),\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=model,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=20,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_model = random_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "print(\"Best Cross-Validation Accuracy:\", random_search.best_score_)\n",
        "print(\"Test Set Accuracy with Best Parameters:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSKVib6erjXA",
        "outputId": "f4160979-6638-4a48-e7df-45856a181146"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': np.float64(7.3299394181140505), 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best Cross-Validation Accuracy: 0.9583333333333334\n",
            "Test Set Accuracy with Best Parameters: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy."
      ],
      "metadata": {
        "id": "w9VSd3aBvFbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "base_lr = LogisticRegression(max_iter=1000, solver='liblinear')\n",
        "\n",
        "ovo_clf = OneVsOneClassifier(base_lr)\n",
        "\n",
        "ovo_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = ovo_clf.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"One-vs-One Logistic Regression Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f6SzZnxr9sF",
        "outputId": "1286cb00-849e-4d59-dcb1-3098b69d9e68"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-vs-One Logistic Regression Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary\n",
        "classification."
      ],
      "metadata": {
        "id": "cljLVUOXwAVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data[iris.target != 2]\n",
        "y = iris.target[iris.target != 2]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Pred 0', 'Pred 1'], yticklabels=['True 0', 'True 1'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "sf2rmoO9wS0u",
        "outputId": "9947fb0b-ebd0-4532-b621-da8a573bfb78"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Write a Python program to train a Logistic Regression model and evaluate its performance using Precision,\n",
        "Recall, and F1-Score."
      ],
      "metadata": {
        "id": "NEbw_ChAwkyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data[iris.target != 2]\n",
        "y = iris.target[iris.target != 2]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall:    {recall:.2f}\")\n",
        "print(f\"F1-Score:  {f1:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKNNeI6FwTpM",
        "outputId": "bc3ae46d-8401-41c2-f567-b6ef0f2ac50a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 1.00\n",
            "Recall:    1.00\n",
            "F1-Score:  1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to\n",
        "improve model performance."
      ],
      "metadata": {
        "id": "4dp_R46PxEVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=20,\n",
        "    n_informative=2,\n",
        "    n_redundant=10,\n",
        "    n_clusters_per_class=1,\n",
        "    weights=[0.9, 0.1],  # 90% of class 0, 10% of class 1\n",
        "    flip_y=0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model_no_weights = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model_no_weights.fit(X_train, y_train)\n",
        "y_pred_no_weights = model_no_weights.predict(X_test)\n",
        "\n",
        "print(\"Performance without class weights:\")\n",
        "print(classification_report(y_test, y_pred_no_weights))\n",
        "\n",
        "model_with_weights = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
        "model_with_weights.fit(X_train, y_train)\n",
        "y_pred_with_weights = model_with_weights.predict(X_test)\n",
        "\n",
        "print(\"\\nPerformance with class weights:\")\n",
        "print(classification_report(y_test, y_pred_with_weights))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIaUbEh-w2g0",
        "outputId": "ebfc1bc0-f812-42bc-da11-7d13a585ecd8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance without class weights:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       230\n",
            "           1       0.95      0.95      0.95        20\n",
            "\n",
            "    accuracy                           0.99       250\n",
            "   macro avg       0.97      0.97      0.97       250\n",
            "weighted avg       0.99      0.99      0.99       250\n",
            "\n",
            "\n",
            "Performance with class weights:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98       230\n",
            "           1       0.73      0.95      0.83        20\n",
            "\n",
            "    accuracy                           0.97       250\n",
            "   macro avg       0.86      0.96      0.90       250\n",
            "weighted avg       0.97      0.97      0.97       250\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and\n",
        "evaluate performance."
      ],
      "metadata": {
        "id": "P74aYjU9xera"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "titanic = sns.load_dataset('titanic')\n",
        "\n",
        "features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
        "target = 'survived'\n",
        "\n",
        "df = titanic[features + [target]]\n",
        "\n",
        "df['age'].fillna(df['age'].median(), inplace=True)\n",
        "df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)\n",
        "\n",
        "\n",
        "df = pd.get_dummies(df, columns=['sex', 'embarked'], drop_first=True)\n",
        "\n",
        "X = df.drop(target, axis=1)\n",
        "y = df[target]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9MYjy42xWaX",
        "outputId": "5700aee5-032f-4a18-e9ff-16a2ab12765a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.84       105\n",
            "           1       0.79      0.74      0.76        74\n",
            "\n",
            "    accuracy                           0.81       179\n",
            "   macro avg       0.81      0.80      0.80       179\n",
            "weighted avg       0.81      0.81      0.81       179\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-3700d9336668>:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['age'].fillna(df['age'].median(), inplace=True)\n",
            "<ipython-input-20-3700d9336668>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['age'].fillna(df['age'].median(), inplace=True)\n",
            "<ipython-input-20-3700d9336668>:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)\n",
            "<ipython-input-20-3700d9336668>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression\n",
        "model. Evaluate its accuracy and compare results with and without scaling."
      ],
      "metadata": {
        "id": "woqT2Ue1x-Zs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model_no_scaling = LogisticRegression(max_iter=1000)\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "acc_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaled = LogisticRegression(max_iter=1000)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "acc_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(f\"Accuracy without scaling: {acc_no_scaling:.4f}\")\n",
        "print(f\"Accuracy with standardization: {acc_scaled:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gHtmSSYx5s3",
        "outputId": "24e0b7c9-06f3-4ade-e398-2e3158027b7d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 1.0000\n",
            "Accuracy with standardization: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score."
      ],
      "metadata": {
        "id": "2048Z6JkygMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data[iris.target != 2]  # Classes 0 and 1 only\n",
        "y = iris.target[iris.target != 2]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_probs = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "roc_auc = roc_auc_score(y_test, y_probs)\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(fpr, tpr, label=f'ROC Curve (area = {roc_auc:.4f})')\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "32Sj9KU4y3OP",
        "outputId": "e406baf6-9db6-41cc-bfc7-6874903393b2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 1.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate\n",
        "accuracy."
      ],
      "metadata": {
        "id": "DPN38dnCzTTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = LogisticRegression(C=0.5, max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy with C=0.5: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6UestxHzAUa",
        "outputId": "eb9d18c0-7297-48d9-a797-4d9b3cb35365"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with C=0.5: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "18. Write a Python program to train Logistic Regression and identify important features based on model\n",
        "coefficients."
      ],
      "metadata": {
        "id": "8MOajeOC0NvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "feature_importance = pd.Series(abs(model.coef_[0]), index=X.columns)\n",
        "feature_importance = feature_importance.sort_values(ascending=False)\n",
        "\n",
        "print(\"Top important features based on Logistic Regression coefficients:\")\n",
        "print(feature_importance.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL2zh1C30fHG",
        "outputId": "9d7d50fd-7ed9-4a33-ea75-992a610cf0b1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top important features based on Logistic Regression coefficients:\n",
            "worst texture           1.350606\n",
            "radius error            1.268178\n",
            "worst symmetry          1.208200\n",
            "mean concave points     1.119804\n",
            "worst concavity         0.943053\n",
            "area error              0.907186\n",
            "worst radius            0.879840\n",
            "worst area              0.841846\n",
            "mean concavity          0.801458\n",
            "worst concave points    0.778217\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Write a Python program to train Logistic Regression and evaluate its performance using Cohen’s Kappa\n",
        "Score."
      ],
      "metadata": {
        "id": "yxd8FzPU0mp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "print(f\"Cohen's Kappa Score: {kappa:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVgX3tME0f8q",
        "outputId": "a5943d1d-823f-4ad1-8d3f-b7e92a5076f3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen's Kappa Score: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary\n",
        "classificatio."
      ],
      "metadata": {
        "id": "JxzL5Nyz1IHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_scores = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_scores)\n",
        "avg_precision = average_precision_score(y_test, y_scores)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.plot(recall, precision, label=f'AP = {avg_precision:.2f}', color='b')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "FThzUsxc1AhP",
        "outputId": "34009dfe-5a77-4757-9414-9c313c871b56"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy"
      ],
      "metadata": {
        "id": "RTih3s_g1gZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "accuracies = {}\n",
        "\n",
        "for solver in solvers:\n",
        "    try:\n",
        "        model = LogisticRegression(solver=solver, max_iter=1000)\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        accuracies[solver] = acc\n",
        "    except Exception as e:\n",
        "        accuracies[solver] = f\"Error: {e}\"\n",
        "\n",
        "print(\"Accuracy comparison of different solvers:\")\n",
        "for solver, acc in accuracies.items():\n",
        "    print(f\"  {solver}: {acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPsftJ9O1WO3",
        "outputId": "6153c5e9-7e4d-4829-c9d6-5e8249317b51"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy comparison of different solvers:\n",
            "  liblinear: 0.9666666666666667\n",
            "  saga: 1.0\n",
            "  lbfgs: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Write a Python program to train Logistic Regression and evaluate its performance using Matthews\n",
        "Correlation Coefficient (MCC)."
      ],
      "metadata": {
        "id": "FBmQetDE17qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "print(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2DP9w1316jx",
        "outputId": "b8fb08fc-4a63-413a-e1d5-77acc411bcaa"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matthews Correlation Coefficient (MCC): 0.9439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. Write a Python program to train Logistic Regression on both raw and standardized data. Compare their\n",
        "accuracy to see the impact of feature scaling."
      ],
      "metadata": {
        "id": "cVMhiqQw2byR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model_raw = LogisticRegression(max_iter=1000)\n",
        "model_raw.fit(X_train, y_train)\n",
        "y_pred_raw = model_raw.predict(X_test)\n",
        "acc_raw = accuracy_score(y_test, y_pred_raw)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaled = LogisticRegression(max_iter=1000)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "acc_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(f\"Accuracy on raw data:         {acc_raw:.4f}\")\n",
        "print(f\"Accuracy on standardized data: {acc_scaled:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8oM2s_Y2a2U",
        "outputId": "d00ac742-9b75-4003-b29e-fd14a648977c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on raw data:         0.9561\n",
            "Accuracy on standardized data: 0.9737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validationM\n"
      ],
      "metadata": {
        "id": "T3QjZU86258R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000, solver='liblinear')\n",
        "param_grid = {'C': np.logspace(-4, 4, 10)}\n",
        "\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Best C value: {grid_search.best_params_['C']}\")\n",
        "print(f\"Test accuracy with best C: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9uZJnBr2rzu",
        "outputId": "0bfa67ee-9c04-443b-e2b2-b88926478489"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best C value: 0.3593813663804626\n",
            "Test accuracy with best C: 0.9825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to\n",
        "make predictions."
      ],
      "metadata": {
        "id": "E6V7nLsr3ahl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "joblib.dump(model, 'logistic_model.joblib')\n",
        "joblib.dump(scaler, 'scaler.joblib')\n",
        "\n",
        "print(\"Model and scaler saved successfully.\")\n",
        "\n",
        "loaded_model = joblib.load('logistic_model.joblib')\n",
        "loaded_scaler = joblib.load('scaler.joblib')\n",
        "\n",
        "X_test_loaded_scaled = loaded_scaler.transform(X_test)\n",
        "y_pred_loaded = loaded_model.predict(X_test_loaded_scaled)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred_loaded)\n",
        "print(f\"Accuracy of loaded model: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdPanxgg3LMv",
        "outputId": "cc8c99af-71d8-4668-ce29-24497b54dd7d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and scaler saved successfully.\n",
            "Accuracy of loaded model: 0.9737\n"
          ]
        }
      ]
    }
  ]
}